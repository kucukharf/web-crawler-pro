{
  "author": "Burak Arslan",
  "dependencies": {
    "archiver": "^1.2.0",
    "axios": "^0.16.1",
    "bluebird": "^3.0.1",
    "chalk": "^1.1.3",
    "cheerio": "0.22.0",
    "css-url-parser": "^1.0.0",
    "debug": "^2.4.5",
    "fs-extra": "^3.0.0",
    "glob": "^7.1.2",
    "he": "^1.1.0",
    "jsonfile": "^3.0.0",
    "lodash": "^4.11.1",
    "normalize-url": "^1.5.3",
    "parse-domain": "^1.1.0",
    "prompt": "^1.0.0",
    "request": "^2.42.0",
    "rimraf": "^2.6.1",
    "srcset": "^1.0.0",
    "string-template": "^1.0.0",
    "time-stamp": "^1.0.1",
    "valid-url": "^1.0.9"
  },
  "description": "Website which crawl websites. Uses nodejs",
  "devDependencies": {
    "clock": "^0.1.6",
    "codeclimate-test-reporter": "^0.4.0",
    "coveralls": "^2.11.8",
    "eslint": "^3.9.1",
    "istanbul": "^0.4.0",
    "mocha": "^3.0.2",
    "nock": "^9.0.2",
    "proxyquire": "^1.7.3",
    "should": "^11.1.0",
    "sinon": "^2.1.0"
  },
  "files": [
    "index.js",
    "lib"
  ],
  "homepage": "https://github.com/kucukharf/web-crawler",
  "license": "MIT",
  "main": "index.js",
  "name": "web-crawler",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git://github.com/kucukharf/web-crawler.git"
  },
  "scripts": {
    "clean": "node clean.js",
    "crawl-wl": "export DEBUG=website-scraper*; node --max_old_space_size=8192 --optimize_for_size --max_executable_size=8192 --stack_size=8192 index.js",
    "crawl": " node --max_old_space_size=8192 --optimize_for_size --max_executable_size=8192 --stack_size=8192 index.js",
    "eslint": "eslint lib/** index.js",
    "load": "node bar.js",
    "start": "node index.js",
    "axios": "node axios.js",
    "test": "istanbul cover node_modules/mocha/bin/_mocha --dir ./coverage --report lcov -- -R spec --recursive --timeout 7000 ./test/unit/ ./test/functional && npm run eslint",
    "test-e2e": "node_modules/mocha/bin/_mocha --timeout 300000 ./test/e2e/*-test.js"
  },
  "version": "0.0.1"
}
